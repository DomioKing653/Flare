use std::error::Error;

use crate::backend::lexer::tokens::TokenKind::{COMMA, FALSE, SEMICOLON, TRUE};
use crate::{
    backend::errors::lexer_errors::LexerError,
    backend::lexer::tokens::{
        Token, TokenKind,
        TokenKind::{
            CLOSINGBRACE, COLON, CONST, DIVIDE, ELSE, EOF, EQUAL, FLOAT, FN, IDENTIFIER, IF,
            LEFTPAREN, LOOP, MINUS, MODULO, NUMB, OPENINGBRACE, PLUS, RIGHTPAREN, STR, TIMES, VAR,
            WHILE,
        },
    },
};

pub struct Tokenizer {
    current_token: char,
    token_idx: usize,
    token_count: usize,
    source_text: Vec<char>,
    final_tokens: Vec<Token>,
}

impl Tokenizer {
    pub fn new(text: String) -> Self {
        Self {
            token_idx: 0,
            token_count: text.len(),
            current_token: '0',
            source_text: text.chars().collect(),
            final_tokens: Vec::new(),
        }
    }
    pub fn tokenize(&mut self) -> Result<&Vec<Token>, Box<dyn Error>> {
        if self.source_text.is_empty() {
            return Err(LexerError::EmptyFile.into());
        }
        self.current_token = self.source_text[0];
        while self.current_token != '\0' {
            match self.current_token {
                ' ' | '\n' | '\t' | '\r' => {
                    self.advance();
                    continue;
                }
                '"' => {
                    let token = self.read_string();
                    self.final_tokens.push(token);
                    continue;
                }
                ':' => self.final_tokens.push(Token {
                    token_kind: COLON,
                    token_value: self.current_token.to_string(),
                }),
                '+' => self.final_tokens.push(Token {
                    token_kind: PLUS,
                    token_value: self.current_token.to_string(),
                }),
                ',' => self.final_tokens.push(Token {
                    token_kind: COMMA,
                    token_value: self.current_token.to_string(),
                }),
                ';' => self.final_tokens.push(Token {
                    token_kind: SEMICOLON,
                    token_value: self.current_token.to_string(),
                }),
                '=' => self.final_tokens.push(Token {
                    token_kind: EQUAL,
                    token_value: self.current_token.to_string(),
                }),
                '(' => self.final_tokens.push(Token {
                    token_kind: LEFTPAREN,
                    token_value: self.current_token.to_string(),
                }),
                ')' => self.final_tokens.push(Token {
                    token_kind: RIGHTPAREN,
                    token_value: self.current_token.to_string(),
                }),
                '{' => self.final_tokens.push(Token {
                    token_kind: OPENINGBRACE,
                    token_value: self.current_token.to_string(),
                }),
                '}' => self.final_tokens.push(Token {
                    token_kind: CLOSINGBRACE,
                    token_value: self.current_token.to_string(),
                }),
                '-' => self.final_tokens.push(Token {
                    token_kind: MINUS,
                    token_value: self.current_token.to_string(),
                }),
                '*' => self.final_tokens.push(Token {
                    token_kind: TIMES,
                    token_value: self.current_token.to_string(),
                }),
                '/' => self.final_tokens.push(Token {
                    token_kind: DIVIDE,
                    token_value: self.current_token.to_string(),
                }),
                '%' => self.final_tokens.push(Token {
                    token_kind: MODULO,
                    token_value: self.current_token.to_string(),
                }),
                '>' => self.final_tokens.push(Token {
                    token_kind: TokenKind::GREATER,
                    token_value: self.current_token.to_string(),
                }),
                '<' => self.final_tokens.push(Token {
                    token_kind: TokenKind::LESS,
                    token_value: self.current_token.to_string(),
                }),
                _ => {
                    if self.current_token.is_alphabetic() {
                        let token = self.create_text_token();
                        self.final_tokens.push(token);
                        continue;
                    } else if self.current_token.is_numeric() {
                        let token = self.create_number_token()?;
                        self.final_tokens.push(token);
                        continue;
                    } else {
                        return Err(LexerError::UnknownToken {
                            wrong_token: self.current_token.to_string(),
                        }
                        .into());
                    }
                }
            }
            self.advance();
        }
        self.final_tokens.push(Token {
            token_kind: EOF,
            token_value: "EOF".to_string(),
        });
        Ok(&self.final_tokens)
    }
    fn advance(&mut self) {
        self.token_idx += 1;
        if self.token_idx >= self.token_count {
            self.current_token = '\0';
        } else {
            self.current_token = self.source_text[self.token_idx];
        }
    }
    fn create_number_token(&mut self) -> Result<Token, LexerError> {
        let mut number_buffer: String = String::new();
        let mut dot_count: usize = 0;
        while self.current_token.is_numeric() || self.current_token == '.' {
            if self.current_token == '.' {
                if dot_count < 1 {
                    dot_count += 1;
                    number_buffer.push('.')
                } else {
                    return Err(LexerError::MoreDotInANumber);
                }
            } else {
                number_buffer.push(self.current_token);
            }
            self.advance();
        }
        Ok(Token {
            token_kind: if dot_count < 1 { NUMB } else { FLOAT },
            token_value: number_buffer,
        })
    }
    fn create_text_token(&mut self) -> Token {
        let mut text_buffer: String = String::new();
        while self.current_token.is_alphabetic()
            || self.current_token.is_numeric()
            || self.current_token == '!'
            || self.current_token == '_'
        {
            text_buffer.push(self.current_token);
            self.advance()
        }
        match text_buffer.as_str() {
            "var" => Token {
                token_kind: VAR,
                token_value: text_buffer,
            },
            "fn" => Token {
                token_kind: FN,
                token_value: text_buffer,
            },
            "str" => Token {
                token_kind: STR,
                token_value: text_buffer,
            },
            "const" => Token {
                token_kind: CONST,
                token_value: text_buffer,
            },
            "true" => Token {
                token_value: text_buffer,
                token_kind: TRUE,
            },
            "false" => Token {
                token_value: text_buffer,
                token_kind: FALSE,
            },
            "if" => Token {
                token_kind: IF,
                token_value: text_buffer,
            },
            "else" => Token {
                token_kind: ELSE,
                token_value: text_buffer,
            },
            "loop" => Token {
                token_kind: LOOP,
                token_value: text_buffer,
            },
            "while" => Token {
                token_kind: WHILE,
                token_value: text_buffer,
            },
            "undef" => Token {
                token_kind: TokenKind::UNDEF,
                token_value: text_buffer,
            },
            _ => Token {
                token_kind: IDENTIFIER,
                token_value: text_buffer,
            },
        }
    }
    fn read_string(&mut self) -> Token {
        self.advance();

        let mut value = String::new();
        while self.current_token != '"' {
            value.push(self.current_token);
            self.advance();
        }

        self.advance();
        Token {
            token_kind: TokenKind::STRING,
            token_value: value,
        }
    }
}
